import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageOps
from deepface import DeepFace
from insightface.app import FaceAnalysis

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="An√°lise Facial", layout="centered")

# Inicializa o modelo InsightFace
@st.cache_resource
def load_insightface():
    try:
        app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])
        app.prepare(ctx_id=0)
        return app
    except Exception as e:
        st.error(f"Erro ao carregar InsightFace: {e}")
        return None

app_insight = load_insightface()

# Fun√ß√µes auxiliares
def translate_gender(gender_id):
    return "Homem" if gender_id == 1 else "Mulher"

def map_age_to_range(age):
    if age <= 12:
        return "Crian√ßa (0-12)"
    elif age <= 17:
        return "Adolescente (13-17)"
    elif age <= 29:
        return "Jovem Adulto (18-29)"
    elif age <= 49:
        return "Adulto (30-49)"
    elif age <= 64:
        return "Meia-idade (50-64)"
    else:
        return "Idoso (65+)"

def translate_emotion(emotion):
    translation = {
        "angry": "Bravo",
        "disgust": "Nojo",
        "fear": "Medo",
        "happy": "Feliz",
        "sad": "Triste",
        "surprise": "Surpreso",
        "neutral": "Neutro",
    }
    return translation.get(emotion, emotion)

def fix_image_orientation(pil_image):
    """Corrige a orienta√ß√£o da imagem baseada nos metadados EXIF"""
    try:
        # Usa ImageOps.exif_transpose para corrigir automaticamente a orienta√ß√£o
        corrected_image = ImageOps.exif_transpose(pil_image)
        return corrected_image
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel corrigir a orienta√ß√£o: {e}")
        return pil_image

def analyze_emotion(frame):
    """Analisa a emo√ß√£o usando DeepFace"""
    try:
        result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)
        if isinstance(result, list) and len(result) > 0:
            return result[0]['dominant_emotion']
        elif isinstance(result, dict):
            return result['dominant_emotion']
        else:
            return "Neutro"
    except Exception as e:
        st.warning(f"Erro na an√°lise emocional: {e}")
        return "Desconhecida"

def process_image(pil_image):
    """Processa a imagem e detecta faces, idade, g√™nero e emo√ß√£o"""
    try:
        # Corrige a orienta√ß√£o da imagem
        pil_image = fix_image_orientation(pil_image)
        
        # Converte PIL para OpenCV
        frame_bgr = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        # Verifica se o modelo foi carregado
        if app_insight is None:
            st.error("Modelo InsightFace n√£o foi carregado corretamente.")
            return np.array(pil_image)
        
        # Detecta faces
        faces = app_insight.get(frame_bgr)
        
        if len(faces) == 0:
            st.warning("Nenhuma face detectada na imagem.")
            return np.array(pil_image)
        
        # Analisa emo√ß√£o uma vez para toda a imagem
        emotion = analyze_emotion(frame_bgr)
        emotion_translated = translate_emotion(emotion)
        
        # Dimens√µes da imagem para escalar fonte
        h, w, _ = frame_bgr.shape
        font_scale = max(0.6, min(w, h) / 800)
        line_height = int(30 * font_scale)
        
        # Processa cada face detectada
        for i, face in enumerate(faces):
            age = int(face.age)
            gender = translate_gender(face.gender)
            faixa = map_age_to_range(age)
            
            # Desenha ret√¢ngulo ao redor da face
            bbox = face.bbox.astype(int)
            cv2.rectangle(frame_bgr, tuple(bbox[:2]), tuple(bbox[2:]), (0, 255, 0), 2)
            
            # Prepara labels
            labels = [
                f"G√™nero: {gender}",
                f"Idade: {age} anos ({faixa})",
                f"Emo√ß√£o: {emotion_translated}"
            ]
            
            # Posi√ß√£o inicial do texto
            x, y = bbox[0], bbox[1] - 15
            
            # Garante que o texto n√£o saia da imagem
            if y < line_height * len(labels):
                y = bbox[3] + line_height
            
            # Desenha cada label
            for j, label in enumerate(labels):
                text_y = y + j * line_height
                
                # Fundo para o texto (melhor legibilidade)
                (text_width, text_height), _ = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 2
                )
                cv2.rectangle(
                    frame_bgr,
                    (x - 5, text_y - text_height - 5),
                    (x + text_width + 5, text_y + 5),
                    (0, 0, 0),
                    -1
                )
                
                # Texto
                cv2.putText(
                    frame_bgr,
                    label,
                    (x, text_y),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    font_scale,
                    (0, 255, 0),
                    2
                )
        
        # Converte de volta para RGB
        return cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        
    except Exception as e:
        st.error(f"Erro no processamento da imagem: {e}")
        return np.array(pil_image)

# Interface do Streamlit
st.title("üì∑ An√°lise Facial com DeepFace + InsightFace")
st.markdown("Envie uma imagem ou use a c√¢mera para detectar idade, g√™nero e emo√ß√£o.")

# Op√ß√µes de entrada
col1, col2 = st.columns(2)

with col1:
    image_input = st.file_uploader(
        "üìÅ Envie uma imagem", 
        type=["jpg", "jpeg", "png"],
        help="Formatos aceitos: JPG, JPEG, PNG"
    )

with col2:
    camera_input = st.camera_input(
        "üì∏ Ou tire uma foto",
        help="Use a c√¢mera do dispositivo"
    )

# Processamento da imagem
if image_input or camera_input:
    try:
        # Carrega a imagem
        uploaded_image = Image.open(image_input or camera_input)
        
        # Mostra a imagem original
        st.subheader("üñºÔ∏è Imagem Original")
        st.image(uploaded_image, caption="Imagem carregada", use_column_width=True)
        
        # Verifica se os modelos est√£o dispon√≠veis
        if app_insight is None:
            st.error("‚ö†Ô∏è Modelo InsightFace n√£o est√° dispon√≠vel. Verifique a instala√ß√£o.")
        else:
            # Processa a imagem
            with st.spinner("üîç Analisando faces, idade, g√™nero e emo√ß√£o..."):
                result_img = process_image(uploaded_image)
            
            # Mostra o resultado
            st.subheader("‚ú® Resultado da An√°lise")
            st.image(result_img, caption="An√°lise completa", use_column_width=True)
            
            # Informa√ß√µes adicionais
            st.info("üí° **Dica:** Para melhores resultados, use imagens com faces bem iluminadas e frontais.")
            
    except Exception as e:
        st.error(f"‚ùå Erro ao processar a imagem: {e}")
        st.markdown("**Poss√≠veis solu√ß√µes:**")
        st.markdown("- Verifique se a imagem est√° em formato v√°lido (JPG, JPEG, PNG)")
        st.markdown("- Tente com uma imagem diferente")
        st.markdown("- Reinicie a aplica√ß√£o")

# Informa√ß√µes sobre a aplica√ß√£o
with st.expander("‚ÑπÔ∏è Sobre esta aplica√ß√£o"):
    st.markdown("""
    **Tecnologias utilizadas:**
    - **InsightFace:** Detec√ß√£o de faces, idade e g√™nero
    - **DeepFace:** An√°lise de emo√ß√µes
    - **OpenCV:** Processamento de imagens
    - **Streamlit:** Interface web
    
    **Funcionalidades:**
    - ‚úÖ Corre√ß√£o autom√°tica de orienta√ß√£o de imagens
    - ‚úÖ Detec√ß√£o de m√∫ltiplas faces
    - ‚úÖ An√°lise de idade, g√™nero e emo√ß√£o
    - ‚úÖ Interface responsiva para mobile
    
    **Nota:** A precis√£o pode variar dependendo da qualidade e ilumina√ß√£o da imagem.
    """)
